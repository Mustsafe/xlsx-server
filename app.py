from flask import Flask, request, jsonify, send_from_directory, Response
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import openai
import difflib
from dateutil import parser
from datetime import datetime, timedelta
from io import BytesIO, StringIO
from typing import List
from urllib.parse import quote

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # í•œê¸€ ê¹¨ì§ ë°©ì§€

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
openai.api_key = os.getenv("OPENAI_API_KEY")

# ./data ë””ë ‰í† ë¦¬ ì‚¬ìš©
DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# --- 1. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ---
@app.route("/health", methods=["GET"])
def health_check():
    return "OK", 200

# í”ŒëŸ¬ê·¸ì¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì„œë¹™
@app.route("/.well-known/<path:filename>")
def serve_well_known(filename):
    return send_from_directory(
        os.path.join(app.root_path, "static", ".well-known"),
        filename,
        mimetype="application/json"
    )

# OpenAPI ë° ë¡œê³  íŒŒì¼ ì„œë¹™
@app.route("/openapi.json")
def serve_openapi():
    return send_from_directory(
        os.path.join(app.root_path, "static"),
        "openapi.json",
        mimetype="application/json"
    )

@app.route("/logo.png")
def serve_logo():
    return send_from_directory(
        os.path.join(app.root_path, "static"),
        "logo.png",
        mimetype="image/png"
    )

# ë„¤ì´ë²„ ì˜¤í”ˆ API ìê²©ì¦ëª… (ë‰´ìŠ¤ í¬ë¡¤ë§ìš©)
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

def build_alias_map(template_list: List[str]) -> dict:
    alias = {}
    SUFFIXES = [" ì ê²€í‘œ", " ê³„íšì„œ", " ì„œì‹", " í‘œ", "ì–‘ì‹", " ì–‘ì‹", "_ì–‘ì‹"]
    for tpl in template_list:
        alias[tpl] = tpl
        alias[tpl.replace("_", " ")] = tpl
        alias[tpl.replace(" ", "_")] = tpl
        low = tpl.lower()
        alias[low] = tpl
        alias[low.replace("_", " ")] = tpl
        base_space = tpl.replace("_", " ")
        nospace = base_space.replace(" ", "").lower()
        alias[nospace] = tpl
        for suf in SUFFIXES:
            combo = base_space + suf
            alias[combo] = tpl
            alias[combo.replace(" ", "_")] = tpl
            alias[combo.lower()] = tpl
    for tpl in template_list:
        norm = tpl.lower().replace(" ", "").replace("_", "")
        if "jsa" in norm or "ì‘ì—…ì•ˆì „ë¶„ì„" in norm:
            alias["__FORCE_JSA__"] = tpl
        if "loto" in norm:
            alias["__FORCE_LOTO__"] = tpl
    temp = {}
    for k, v in alias.items():
        temp[k.replace(" ", "_")] = v
        temp[k.replace("_", " ")] = v
    alias.update(temp)
    return alias

def resolve_keyword(raw_keyword: str, template_list: List[str], alias_map: dict) -> str:
    raw = raw_keyword.strip()
    norm = raw.replace("_", " ").replace("-", " ")
    key_lower = norm.lower()
    cleaned_key = key_lower.replace(" ", "")
    if "__FORCE_JSA__" in alias_map and ("jsa" in cleaned_key or "ì‘ì—…ì•ˆì „ë¶„ì„" in cleaned_key):
        return alias_map["__FORCE_JSA__"]
    if "__FORCE_LOTO__" in alias_map and "loto" in cleaned_key:
        return alias_map["__FORCE_LOTO__"]
    for tpl in template_list:
        tpl_norm = tpl.lower().replace(" ", "").replace("_", "")
        if key_lower == tpl.lower() or cleaned_key == tpl_norm:
            return tpl
    tokens = [t for t in key_lower.split(" ") if t]
    candidates = [tpl for tpl in template_list if all(tok in tpl.lower() for tok in tokens)]
    if len(candidates) == 1:
        return candidates[0]
    substr_cands = [
        tpl for tpl in template_list
        if cleaned_key in tpl.lower().replace(" ", "").replace("_", "")
    ]
    if len(substr_cands) == 1:
        return substr_cands[0]
    if raw in alias_map:
        return alias_map[raw]
    if key_lower in alias_map:
        return alias_map[key_lower]
    candidates_norm = [t.replace(" ", "").replace("_", "").lower() for t in template_list]
    matches = difflib.get_close_matches(cleaned_key, candidates_norm, n=1, cutoff=0.6)
    if matches:
        return template_list[candidates_norm.index(matches[0])]
    raise ValueError(f"í…œí”Œë¦¿ â€˜{raw_keyword}â€™ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def ask_gpt_for_default(template_name: str) -> pd.DataFrame:
    """
    ê³ ë„í™” ëª©ë¡ì— ì—†ëŠ” í…œí”Œë¦¿ì¼ ë•Œ, GPTì—ê²Œ ê¸°ë³¸ ì–‘ì‹ì„ ìƒì„±í•´ ë‹¬ë¼ê³  ìš”ì²­í•˜ê³ 
    ê·¸ ê²°ê³¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ DataFrameìœ¼ë¡œ íŒŒì‹±í•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    prompt_system = {
        "role": "system",
        "content": (
            "ë‹¹ì‹ ì€ ì‚°ì—…ì•ˆì „ë³´ê±´ ê´€ë ¨ ë¬¸ì„œ í…œí”Œë¦¿ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
            "ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì–‘ì‹ëª…ì´ CSVì— ì—†ì„ ë•Œ, ì•„ë˜ê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ìì„¸íˆ ê¸°ë³¸ í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n\n"
            "- ë¬¸ì„œëª…: ìš”ì²­ëœ ì œëª©\n"
            "- ë²•ì  ê·¼ê±°: ê´€ë ¨ ë²•ë ¹ëª…Â·ì¡°ë¬¸ ë²ˆí˜¸ ë° ì¶œì²˜\n"
            "- ì œì¶œë°©ë²• ë˜ëŠ” ë¹„ê³ \n\n"
            "ê·¸ë¦¬ê³  ë‘ ì¹¼ëŸ¼(â€˜í•­ëª©â€™, â€˜ê¸°ì… ë‚´ìš©â€™)ìœ¼ë¡œ êµ¬ì„±ëœ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”."
        )
    }
    prompt_user = {"role": "user", "content": f"í…œí”Œë¦¿ëª…: {template_name}"}
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[prompt_system, prompt_user],
        temperature=0.5,
        max_tokens=600
    )
    md = resp.choices[0].message.content

    # ë§ˆí¬ë‹¤ìš´ í‘œë§Œ ì¶”ì¶œí•´ì„œ DataFrameìœ¼ë¡œ ë³€í™˜
    # ```markdown
    # |í•­ëª©|ê¸°ì… ë‚´ìš©|
    # |---|---|
    # |ì‚¬ì—…ì¥ ëª…|...|
    # ...
    # ```
    # ê°„ë‹¨íˆ |ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ë§Œ ëª¨ì•„ì„œ íŒŒì‹±
    lines = [l for l in md.splitlines() if l.strip().startswith("|")]
    table_md = "\n".join(lines)
    # íŒë‹¤ìŠ¤ê°€ ë§ˆí¬ë‹¤ìš´ ì½ê¸°ëŠ” ì§€ì› ì•ˆ í•˜ë¯€ë¡œ, íƒ­ êµ¬ë¶„ìœ¼ë¡œ ë³€í™˜
    table_txt = table_md.replace("|", "\t").strip()
    df = pd.read_csv(StringIO(table_txt), sep="\t", engine="python")
    return df

@app.route("/", methods=["GET"])
def index():
    return "ğŸ“° ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸: /health, /daily_news, /render_news, /create_xlsx, /list_templates", 200

@app.route("/create_xlsx", methods=["GET"])
def create_xlsx():
    raw = request.args.get("template", "")
    csv_path = os.path.join(DATA_DIR, "í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(csv_path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."), 404

    df = pd.read_csv(csv_path)
    if "í…œí”Œë¦¿ëª…" not in df.columns:
        return jsonify(error="í•„ìš”í•œ 'í…œí”Œë¦¿ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."), 500

    template_list = sorted(df["í…œí”Œë¦¿ëª…"].dropna().unique().tolist())
    alias_map     = build_alias_map(template_list)

    try:
        # ê³ ë„í™” ëª©ë¡ì—ì„œ ì°¾ì•„ì„œ
        tpl = resolve_keyword(raw, template_list, alias_map)
        filtered = df[df["í…œí”Œë¦¿ëª…"] == tpl]
        out_df   = filtered[["ì‘ì—… í•­ëª©", "ì‘ì„± ì–‘ì‹", "ì‹¤ë¬´ ì˜ˆì‹œ 1", "ì‹¤ë¬´ ì˜ˆì‹œ 2"]]
    except ValueError:
        # ì—†ìœ¼ë©´ GPTì—ê²Œ ê¸°ë³¸ ì–‘ì‹ ìƒì„± ìš”ì²­
        out_df = ask_gpt_for_default(raw)

    # ì—‘ì…€ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    def generate_xlsx():
        buf = BytesIO()
        out_df.to_excel(buf, index=False)
        buf.seek(0)
        while True:
            chunk = buf.read(8192)
            if not chunk:
                break
            yield chunk

    filename    = f"{raw or 'default'}.xlsx"
    disposition = "attachment; filename*=UTF-8''" + quote(filename)
    headers     = {
        "Content-Type": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "Content-Disposition": disposition,
        "Cache-Control": "public, max-age=3600"
    }
    return Response(generate_xlsx(), headers=headers)

@app.route("/list_templates", methods=["GET"])
def list_templates():
    csv_path = os.path.join(DATA_DIR, "í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(csv_path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."), 404
    df            = pd.read_csv(csv_path)
    template_list = sorted(df["í…œí”Œë¦¿ëª…"].dropna().unique().tolist())
    alias_map     = build_alias_map(template_list)
    return jsonify({
        "template_list": template_list,
        "alias_keys":    sorted(alias_map.keys())
    })

# ì´í•˜ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° /daily_news, /render_news ì—”ë“œí¬ì¸íŠ¸ëŠ” ê¸°ì¡´ê³¼ ë™ì¼
# ...

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))

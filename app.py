from flask import Flask, request, jsonify, send_from_directory, Response
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import openai
import difflib
from dateutil import parser
from datetime import datetime, timedelta
from io import BytesIO
from typing import List
from urllib.parse import quote
import json
import logging
from openpyxl import Workbook
from openpyxl.styles import Font

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False

openai.api_key = os.getenv("OPENAI_API_KEY")
NAVER_CLIENT_ID     = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ë¦¬í‹°: alias ë§µ ìƒì„± & í‚¤ì›Œë“œ ë§¤í•‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_alias_map(template_list: List[str]) -> dict:
    alias = {}
    SUFFIXES = [" ì ê²€í‘œ"," ê³„íšì„œ"," ì„œì‹"," í‘œ","ì–‘ì‹"," ì–‘ì‹","_ì–‘ì‹"]
    for tpl in template_list:
        alias[tpl] = tpl
        alias[tpl.replace("_"," ")] = tpl
        alias[tpl.replace(" ","_")] = tpl
        low = tpl.lower()
        alias[low] = tpl
        alias[low.replace("_"," ")] = tpl
        base = tpl.replace("_"," ")
        combo_keys = [base, base.replace(" ",""), low, low.replace(" ","")]
        for k in combo_keys:
            alias[k] = tpl
            for suf in SUFFIXES:
                alias[(k + suf)] = tpl
    # JSA / LOTO ê°•ì œ ë§¤í•‘ í‚¤
    normed = [t.lower().replace(" ","").replace("_","") for t in template_list]
    for tpl,n in zip(template_list,normed):
        if "jsa" in n or "ì‘ì—…ì•ˆì „ë¶„ì„" in n: alias["__FORCE_JSA__"] = tpl
        if "loto" in n:               alias["__FORCE_LOTO__"] = tpl
    return alias

def resolve_keyword(raw: str, templates: List[str], alias_map: dict) -> str:
    key = raw.strip()
    norm = key.replace("_"," ").replace("-"," ").lower()
    compact = norm.replace(" ","")
    # ì›ë¬¸ ì¼ì¹˜
    for tpl in templates:
        if key==tpl or key.replace("_"," ")==tpl or key.replace(" ","_")==tpl:
            return tpl
    # JSA/LOTO ìš°ì„ 
    if "__FORCE_JSA__" in alias_map and ("jsa" in compact or "ì‘ì—…ì•ˆì „ë¶„ì„" in compact):
        return alias_map["__FORCE_JSA__"]
    if "__FORCE_LOTO__" in alias_map and "loto" in compact:
        return alias_map["__FORCE_LOTO__"]
    # compact ì¼ì¹˜
    for tpl in templates:
        if compact == tpl.lower().replace(" ","").replace("_",""):
            return tpl
    # í† í° ë§¤ì¹­
    tokens = [t for t in norm.split() if t]
    cands = [tpl for tpl in templates if all(tok in tpl.lower() for tok in tokens)]
    if len(cands)==1: return cands[0]
    # alias ë§µ
    if key in alias_map: return alias_map[key]
    if norm in alias_map: return alias_map[norm]
    # fuzzy
    keys = [t.replace(" ","").replace("_","").lower() for t in templates]
    m = difflib.get_close_matches(compact, keys, n=1, cutoff=0.7)
    if m: return templates[keys.index(m[0])]
    raise ValueError(f"í…œí”Œë¦¿ '{raw}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í—¬ìŠ¤ì²´í¬ & ì •ì  íŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/health", methods=["GET"])
def health_check():
    return "OK", 200

@app.route("/.well-known/<path:filename>")
def serve_well_known(filename):
    return send_from_directory(os.path.join(app.root_path,"static",".well-known"), filename, mimetype="application/json")

@app.route("/openapi.json")
def serve_openapi():
    return send_from_directory(os.path.join(app.root_path,"static"), "openapi.json", mimetype="application/json")

@app.route("/logo.png")
def serve_logo():
    return send_from_directory(os.path.join(app.root_path,"static"), "logo.png", mimetype="image/png")

@app.route("/", methods=["GET"])
def index():
    return "ğŸ“° endpoints: /health, /daily_news, /render_news, /create_xlsx, /list_templates", 200

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—‘ì…€ ìƒì„±: /create_xlsx
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/create_xlsx", methods=["GET"])
def create_xlsx():
    raw = request.args.get("template","")
    logger.info(f"create_xlsx called with template={raw}")
    csv_path = os.path.join(DATA_DIR,"í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(csv_path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."),404
    df = pd.read_csv(csv_path)
    if "í…œí”Œë¦¿ëª…" not in df.columns:
        return jsonify(error="í•„ìš”í•œ 'í…œí”Œë¦¿ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."),500

    templates = sorted(df["í…œí”Œë¦¿ëª…"].dropna().unique().tolist())
    alias_map  = build_alias_map(templates)

    try:
        tpl = resolve_keyword(raw, templates, alias_map)
        out_df = df[df["í…œí”Œë¦¿ëª…"]==tpl][["ì‘ì—… í•­ëª©","ì‘ì„± ì–‘ì‹","ì‹¤ë¬´ ì˜ˆì‹œ 1","ì‹¤ë¬´ ì˜ˆì‹œ 2"]]
    except ValueError as e:
        logger.warning(str(e))
        # GPT fallback: ê³ ë„í™” ìˆ˜ì¤€ JSON
        system = {
            "role":"system",
            "content":(
                "ë‹¹ì‹ ì€ ì‚°ì—…ì•ˆì „ ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
                "ì•„ë˜ ì»¬ëŸ¼ êµ¬ì¡°ì— ë§ì¶° 5ê°œ ì´ìƒì˜ í•­ëª©ì„ ê°–ì¶˜ **JSON ë°°ì—´**ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\n"
                "ì»¬ëŸ¼: ì‘ì—… í•­ëª©, ì‘ì„± ì–‘ì‹, ì‹¤ë¬´ ì˜ˆì‹œ 1, ì‹¤ë¬´ ì˜ˆì‹œ 2\n"
                f"í…œí”Œë¦¿ëª…: {raw}"
            )
        }
        user = {"role":"user","content":f"í…œí”Œë¦¿ëª… '{raw}'ì— ëŒ€í•œ ê¸°ë³¸ ì–‘ì‹ì„ JSON ë°°ì—´ë¡œ ì£¼ì„¸ìš”."}
        resp = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[system,user],
            max_tokens=800,
            temperature=0.5
        )
        txt = resp.choices[0].message.content
        try:
            data = json.loads(txt)
            out_df = pd.DataFrame(data)
        except:
            out_df = pd.DataFrame([{"ì‘ì—… í•­ëª©":raw, "ì‘ì„± ì–‘ì‹":txt, "ì‹¤ë¬´ ì˜ˆì‹œ 1":"", "ì‹¤ë¬´ ì˜ˆì‹œ 2":""}])

    # ì›Œí¬ë¶ ìƒì„±
    wb = Workbook()
    ws = wb.active
    ws.append(list(out_df.columns))
    for cell in ws[1]:
        cell.font = Font(bold=True)
    for row in out_df.itertuples(index=False):
        ws.append(row)

    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)

    fname = f"{tpl if 'tpl' in locals() else raw}.xlsx"
    disp = "attachment; filename*=UTF-8''" + quote(fname)
    headers = {
        "Content-Type":"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "Content-Disposition":disp,
        "Cache-Control":"public, max-age=3600"
    }
    return Response(buffer.read(), headers=headers)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…œí”Œë¦¿ ëª©ë¡: /list_templates
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/list_templates", methods=["GET"])
def list_templates():
    csv_path = os.path.join(DATA_DIR,"í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(csv_path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."),404
    df = pd.read_csv(csv_path)
    templates = sorted(df["í…œí”Œë¦¿ëª…"].dropna().unique())
    return jsonify({"template_list":templates, "alias_keys":sorted(build_alias_map(templates).keys())})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‰´ìŠ¤ í¬ë¡¤ë§ & í”ŒëŸ¬ê·¸ì¸: /daily_news, /render_news
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_safetynews_article_content(url):
    try:
        resp = requests.get(url, headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(resp.text,"html.parser")
        node = soup.select_one("div#article-view-content-div")
        return node.get_text("\n").strip() if node else "(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"
    except:
        return "(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"

def crawl_naver_news():
    base = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id":NAVER_CLIENT_ID,"X-Naver-Client-Secret":NAVER_CLIENT_SECRET}
    kws = ["ê±´ì„¤ ì‚¬ê³ ","ì¶”ë½ ì‚¬ê³ ","ë¼ì„ ì‚¬ê³ ","ì§ˆì‹ ì‚¬ê³ ","í­ë°œ ì‚¬ê³ ","ì‚°ì—…ì¬í•´","ì‚°ì—…ì•ˆì „"]
    out=[]
    for kw in kws:
        r = requests.get(base, headers=headers, params={"query":kw,"display":2,"sort":"date"}, timeout=10)
        if r.status_code!=200: continue
        for it in r.json().get("items",[]):
            t = BeautifulSoup(it["title"],"html.parser").get_text()
            d = BeautifulSoup(it["description"],"html.parser").get_text()
            out.append({"ì¶œì²˜":it.get("originallink","ë„¤ì´ë²„"),"ì œëª©":t,"ë§í¬":it.get("link",""),"ë‚ ì§œ":it.get("pubDate",""),"ë³¸ë¬¸":d})
    return out

def crawl_safetynews():
    base="https://www.safetynews.co.kr"
    kws=["ê±´ì„¤ ì‚¬ê³ ","ì¶”ë½ ì‚¬ê³ ","ë¼ì„ ì‚¬ê³ ","ì§ˆì‹ ì‚¬ê³ ","í­ë°œ ì‚¬ê³ ","ì‚°ì—…ì¬í•´","ì‚°ì—…ì•ˆì „"]
    out=[]
    for kw in kws:
        r = requests.get(f"{base}/search/news?searchword={kw}", headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
        if r.status_code!=200: continue
        soup = BeautifulSoup(r.text,"html.parser")
        for item in soup.select(".article-list-content")[:2]:
            t = item.select_one(".list-titles")
            href = base + t["href"] if t and t.get("href") else None
            dt  = item.select_one(".list-dated")
            content = fetch_safetynews_article_content(href) if href else ""
            out.append({"ì¶œì²˜":"ì•ˆì „ì‹ ë¬¸","ì œëª©":t.get_text(strip=True) if t else "","ë§í¬":href,"ë‚ ì§œ":dt.get_text(strip=True) if dt else "","ë³¸ë¬¸":content[:1000]})
    return out

@app.route("/daily_news", methods=["GET"])
def get_daily_news():
    news = crawl_naver_news() + crawl_safetynews()
    if not news: return jsonify(error="ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."),200
    return jsonify(news)

@app.route("/render_news", methods=["GET"])
def render_news():
    items = []
    cutoff = datetime.utcnow() - timedelta(days=3)
    for n in (crawl_naver_news()+crawl_safetynews()):
        try:
            dt = parser.parse(n["ë‚ ì§œ"])
            if dt>=cutoff:
                n["ë‚ ì§œ"] = dt.strftime("%Y.%m.%d")
                items.append(n)
        except: continue
    items = sorted(items, key=lambda x: parser.parse(x["ë‚ ì§œ"]), reverse=True)[:3]
    if not items: return jsonify(error="ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."),200

    # í”ŒëŸ¬ê·¸ì¸ ê°€ì´ë“œ ì¶œë ¥ êµ¬ì¡°
    formatted = ""
    for n in items:
        formatted += f"ğŸ“° â€œ{n['ì œëª©']}â€ ({n['ë‚ ì§œ']}, {n['ì¶œì²˜']})\n{n['ë³¸ë¬¸']}\n\n"
    return jsonify(rendered_news=formatted)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT",5000)))

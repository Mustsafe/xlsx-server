from flask import Flask, request, jsonify, Response
import pandas as pd
import os
import re
import json
import difflib
import requests
from bs4 import BeautifulSoup
from io import BytesIO
from typing import List
from urllib.parse import quote
from datetime import datetime, timedelta
from dateutil import parser
import openai
import logging

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils import get_column_letter

# â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# â”€â”€ ì•± ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False

openai.api_key      = os.getenv("OPENAI_API_KEY")
NAVER_CLIENT_ID     = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# â”€â”€ ìœ í‹¸: ì†Œë¬¸ì+í•œê¸€+ìˆ«ìë§Œ ë‚¨ê¸°ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sanitize(text: str) -> str:
    return re.sub(r"[^0-9a-zê°€-í£]", "", text.lower())

# â”€â”€ alias_map ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_alias_map(template_list: List[str]) -> dict:
    alias = {}
    SUFFIXES = ["ì ê²€í‘œ","ê³„íšì„œ","ì„œì‹","í‘œ","ì–‘ì‹"]
    for tpl in template_list:
        low = tpl.lower()
        alias[low] = tpl
        alias[low.replace(" ", "_")] = tpl
        alias[low.replace("_", " ")] = tpl
        alias[sanitize(low)] = tpl
        base = re.sub(r"(ì„œì‹|ì–‘ì‹|ì ê²€í‘œ|ê³„íšì„œ|í‘œ)$", "", low).strip()
        for suf in SUFFIXES:
            key = sanitize(base + suf)
            alias[key] = tpl
    for tpl in template_list:
        s = sanitize(tpl)
        if "jsa" in s:
            alias["jsa"] = tpl
        if "loto" in s:
            alias["loto"] = tpl
    for tpl in template_list:
        words = re.findall(r"[0-9a-zê°€-í£]+", tpl.lower())
        for w in words:
            alias[sanitize(w)] = tpl
    return alias

# â”€â”€ í‚¤ì›Œë“œ â†’ í…œí”Œë¦¿ resolve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_keyword(raw: str, templates: List[str], alias_map: dict, freq: dict) -> str:
    query = re.sub(
        r"\s*(?:ì–‘ì‹|ì„œì‹|ì ê²€í‘œ|ê³„íšì„œ|í‘œ)(?:ì„|ë¥¼)?\s*(?:ì£¼ì„¸ìš”|ì¤˜|ë‹¬ë¼|ì „ë‹¬)?$", "",
        raw.strip(), flags=re.IGNORECASE
    ).lower()
    key = sanitize(query)
    if key in alias_map:
        return alias_map[key]
    # fuzzy and substring matching
    matches = difflib.get_close_matches(key, [sanitize(t) for t in templates], n=1, cutoff=0.6)
    if matches:
        return templates[[sanitize(t) for t in templates].index(matches[0])]
    raise ValueError(f"í…œí”Œë¦¿ '{raw}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€ í…œí”Œë¦¿ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/list_templates", methods=["GET"])
def list_templates():
    path = os.path.join(DATA_DIR, "í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."), 404
    df = pd.read_csv(path, encoding="utf-8-sig")
    templates = df["í…œí”Œë¦¿ëª…"].dropna().unique().tolist()
    alias_map = build_alias_map(templates)
    return jsonify({"template_list": templates, "alias_keys": list(alias_map.keys())})

# â”€â”€ ì—‘ì…€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/create_xlsx", methods=["GET"])
def create_xlsx():
    raw = request.args.get("template", "")
    path = os.path.join(DATA_DIR, "í†µí•©_ë…¸ì§€íŒŒì¼.csv")
    if not os.path.exists(path):
        return jsonify(error="í†µí•© CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."), 404
    df = pd.read_csv(path, encoding="utf-8-sig")
    templates = df["í…œí”Œë¦¿ëª…"].dropna().unique().tolist()
    freq = df["í…œí”Œë¦¿ëª…"].value_counts().to_dict()
    alias_map = build_alias_map(templates)
    try:
        tpl = resolve_keyword(raw, templates, alias_map, freq)
        out_df = df[df["í…œí”Œë¦¿ëª…"] == tpl][["ì‘ì—… í•­ëª©","ì‘ì„± ì–‘ì‹","ì‹¤ë¬´ ì˜ˆì‹œ 1","ì‹¤ë¬´ ì˜ˆì‹œ 2"]].copy()
    except ValueError:
        system = {"role":"system","content":"ì‚°ì—…ì•ˆì „ í…œí”Œë¦¿ ì „ë¬¸ê°€. JSON ë°°ì—´ ìƒì„±."}
        user = {"role":"user","content":f"í…œí”Œë¦¿ëª… '{raw}' ê¸°ë³¸ ì–‘ì‹ JSON ë°°ì—´ë¡œ ì£¼ì„¸ìš”."}
        resp = openai.ChatCompletion.create(model="gpt-4o-mini", messages=[system, user], max_tokens=800)
        try:
            out_df = pd.DataFrame(json.loads(resp.choices[0].message.content))
        except:
            out_df = pd.DataFrame([{"ì‘ì—… í•­ëª©": raw, "ì‘ì„± ì–‘ì‹": resp.choices[0].message.content, "ì‹¤ë¬´ ì˜ˆì‹œ 1": "", "ì‹¤ë¬´ ì˜ˆì‹œ 2": ""}])
    # â”€â”€ AI ë™ì  ê³ ë„í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for idx, row in out_df.iterrows():
        # ì‘ì„± ì–‘ì‹ ê³ ë„í™”
        base = row["ì‘ì„± ì–‘ì‹"]
        if isinstance(base,str) and len(base.splitlines())<3:
            sys_msg = {"role":"system","content":"5~8ê°œ ì ê²€ ë¦¬ìŠ¤íŠ¸ JSON ë°°ì—´ë¡œ ìƒì„±."}
            usr_msg = {"role":"user","content":json.dumps({"base": base})}
            try:
                r = openai.ChatCompletion.create(model="gpt-4o-mini", messages=[sys_msg, usr_msg], max_tokens=300)
                items = json.loads(r.choices[0].message.content)
                out_df.at[idx, "ì‘ì„± ì–‘ì‹"] = "\n".join(items)
            except: pass
        # ì‹¤ë¬´ ì˜ˆì‹œ ê³ ë„í™”
        for ex in ["ì‹¤ë¬´ ì˜ˆì‹œ 1","ì‹¤ë¬´ ì˜ˆì‹œ 2"]:
            ex_base = row.get(ex,"")
            if ex_base:
                sysg = {"role":"system","content":"êµ¬ì²´ì  í˜„ì¥ ì‚¬ë¡€ í•œ ë¬¸ì¥ ì„¤ëª…."}
                usrg = {"role":"user","content":json.dumps({"base": ex_base})}
                try:
                    rr = openai.ChatCompletion.create(model="gpt-4o-mini", messages=[sysg, usrg], max_tokens=100)
                    out_df.at[idx, ex] = rr.choices[0].message.content.strip()
                except: pass
    # ìˆœì„œ ì¬ì •ë ¬
    order = ["ğŸ“‹ ì‘ì—… ì ˆì°¨","ğŸ’¡ ì‹¤ë¬´ ê°€ì´ë“œ","âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸","ğŸ› ï¸ ìœ ì§€ë³´ìˆ˜ í¬ì¸íŠ¸","ğŸ“ ì¶œì²˜"]
    out_df["_order"] = out_df["ì‘ì—… í•­ëª©"].apply(lambda x: order.index(x) if x in order else 99)
    out_df = out_df.sort_values("_order").drop(columns=["_order"])
    # ì—‘ì…€ ìƒì„± & í¬ë§·
    wb = Workbook(); ws = wb.active
    headers = ["ì‘ì—… í•­ëª©","ì‘ì„± ì–‘ì‹","ì‹¤ë¬´ ì˜ˆì‹œ 1","ì‹¤ë¬´ ì˜ˆì‹œ 2"]
    ws.append(headers)
    for cell in ws[1]: cell.font=Font(bold=True); cell.alignment=Alignment(horizontal="center", vertical="center")
    for row in out_df.itertuples(index=False): ws.append(row)
    for i,col in enumerate(ws.columns,1):
        mx = max(len(str(c.value or "")) for c in col)
        ws.column_dimensions[get_column_letter(i)].width = min(mx+2,60)
        for cell in col[1:]: cell.alignment = Alignment(wrap_text=True, vertical="top", horizontal="left")
    buf = BytesIO(); wb.save(buf); buf.seek(0)
    disp = quote(f"{tpl}.xlsx")
    return Response(buf.read(), headers={
        "Content-Type":"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "Content-Disposition":f"attachment; filename*=UTF-8''{disp}",
        "Cache-Control":"public, max-age=3600"
    })

# â”€â”€ ë‰´ìŠ¤ í¬ë¡¤ë§ & ë Œë”ë§ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_safetynews_article_content(url):
    try:
        r = requests.get(url, headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        node = soup.select_one("div#article-view-content-div")
        return node.get_text("\n").strip() if node else ""
    except:
        return ""

def crawl_naver_news():
    base = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    kws = ["ê±´ì„¤ ì‚¬ê³ ","ì¶”ë½ ì‚¬ê³ ","ë¼ì„ ì‚¬ê³ ","ì§ˆì‹ ì‚¬ê³ ","í­ë°œ ì‚¬ê³ ","ì‚°ì—…ì¬í•´","ì‚°ì—…ì•ˆì „"]
    out=[]
    for kw in kws:
        r = requests.get(base, headers=headers, params={"query":kw,"display":2,"sort":"date"}, timeout=10)
        if r.status_code==200:
            for item in r.json().get("items",[]):
                title=BeautifulSoup(item["title"],"html.parser").get_text()
                desc=BeautifulSoup(item["description"],"html.parser").get_text()
                out.append({"ì¶œì²˜":item.get("originallink","ë„¤ì´ë²„"),"ì œëª©":title,"ë§í¬":item.get("link",""),"ë‚ ì§œ":item.get("pubDate",""),"ë³¸ë¬¸":desc})
    return out

def crawl_safetynews():
    base="https://www.safetynews.co.kr"
    kws=["ê±´ì„¤ ì‚¬ê³ ","ì¶”ë½ ì‚¬ê³ ","ë¼ì„ ì‚¬ê³ ","ì§ˆì‹ ì‚¬ê³ ","í­ë°œ ì‚¬ê³ ","ì‚°ì—…ì¬í•´","ì‚°ì—…ì•ˆì „"]
    out=[]
    for kw in kws:
        r=requests.get(f"{base}/search/news?searchword={kw}",headers={"User-Agent":"Mozilla/5.0"},timeout=10)
        if r.status_code==200:
            soup=BeautifulSoup(r.text,"html.parser")
            for item in soup.select(".article-list-content")[:2]:
                t=item.select_one(".list-titles")
                href=base+t["href"] if t and t.get("href") else ""
                d=item.select_one(".list-dated")
                content=fetch_safetynews_article_content(href) if href else ""
                out.append({"ì¶œì²˜":"ì•ˆì „ì‹ ë¬¸","ì œëª©":t.get_text(strip=True) if t else "","ë§í¬":href,"ë‚ ì§œ":d.get_text(strip=True) if d else "","ë³¸ë¬¸":content[:1000]})
    return out

@app.route("/daily_news", methods=["GET"])
def get_daily_news():
    news=crawl_naver_news()+crawl_safetynews()
    return jsonify(news if news else {"error":"ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."})

@app.route("/render_news", methods=["GET"])
def render_news():
    news=crawl_naver_news()+crawl_safetynews()
    cutoff=datetime.utcnow()-timedelta(days=3)
    filtered=[{**n, "ë‚ ì§œ":parser.parse(n["ë‚ ì§œ"]).strftime("%Y.%m.%d")} for n in news if parser.parse(n["ë‚ ì§œ"])>=cutoff]
    items=sorted(filtered, key=lambda x: parser.parse(x["ë‚ ì§œ"]), reverse=True)[:3]
    if not items: return jsonify(error="ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."),200
    template="ğŸ“Œ ì‚°ì—… ì•ˆì „ ë° ë³´ê±´ ìµœì‹  ë‰´ìŠ¤\nğŸ“° â€œ{title}â€ ({date}, {ì¶œì²˜})\n\n{ë³¸ë¬¸}\nğŸ” ë” ë³´ë ¤ë©´ â€œë‰´ìŠ¤ ë” ë³´ì—¬ì¤˜â€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    system_msg={"role":"system","content":f"ë‹¤ìŒ JSON í˜•ì‹ì˜ ë‰´ìŠ¤ ëª©ë¡ì„ ì•„ë˜ í…œí”Œë¦¿ì— ë§ì¶° ì¶œë ¥í•˜ì„¸ìš”.\ní…œí”Œë¦¿:\n{template}"}
    user_msg={"role":"user","content":str(items)}
    resp=openai.chat.completions.create(model="gpt-4o-mini",messages=[system_msg,user_msg],max_tokens=800,temperature=0.7)
    return jsonify(formatted_news=resp.choices[0].message.content)

if __name__=="__main__":
    app.run(host="0.0.0.0",port=int(os.getenv("PORT",5000)))

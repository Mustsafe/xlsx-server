from flask import Flask, request, send_file, jsonify
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import openai
from dateutil import parser
from datetime import datetime, timedelta

app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # í•œê¸€ ê¹¨ì§ ë°©ì§€

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
openai.api_key = os.getenv("OPENAI_API_KEY")

# ./data ë””ë ‰í† ë¦¬ ì‚¬ìš©
DATA_DIR = "./data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

from flask import send_from_directory

# (ê¸°ì¡´ ì½”ë“œ ìœ„ìª½ì— ë„£ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤)

# â¶ í”ŒëŸ¬ê·¸ì¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì„œë¹™
@app.route("/.well-known/<path:filename>")
def serve_well_known(filename):
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸/static/.well-known í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°
    return send_from_directory(
        os.path.join(app.root_path, "static", ".well-known"),
        filename,
        mimetype="application/json"
    )

from flask import send_from_directory
import os

# â· OpenAPI ìŠ¤í™ê³¼ ë¡œê³  íŒŒì¼ë„ ë£¨íŠ¸ì—ì„œ ë°”ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ
@app.route("/openapi.json")
def serve_openapi():
    return send_from_directory(
        # directory ì¸ì: ì‹¤ì œ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        os.path.join(app.root_path, "static"),
        # filename ì¸ì: ê·¸ ë””ë ‰í† ë¦¬ ì•ˆì˜ íŒŒì¼ ì´ë¦„
        "openapi.json",
        mimetype="application/json"
    )

@app.route("/logo.png")
def serve_logo():
    return send_from_directory(
        os.path.join(app.root_path, "static"),
        "logo.png",
        mimetype="image/png"
    )


# ë„¤ì´ë²„ ì˜¤í”ˆ API ìê²©ì¦ëª… (ì‹¤ì œë¡  í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬)
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# ì‘ì—…ê³„íšì„œ í‚¤ì›Œë“œ ë§¤í•‘ (ì „ë¶€ í¬í•¨)
KEYWORD_ALIAS = {
    "ê³ ì†Œì‘ì—… ê³„íšì„œ": "ê³ ì†Œì‘ì—…ëŒ€ì‘ì—…ê³„íšì„œ", "ê³ ì†Œ ì‘ì—… ê³„íšì„œ": "ê³ ì†Œì‘ì—…ëŒ€ì‘ì—…ê³„íšì„œ",
    "ê³ ì†Œì‘ì—…ëŒ€ ê³„íšì„œ": "ê³ ì†Œì‘ì—…ëŒ€ì‘ì—…ê³„íšì„œ", "ê³ ì†Œì‘ì—…": "ê³ ì†Œì‘ì—…ëŒ€ì‘ì—…ê³„íšì„œ",
    "ë°€íê³µê°„ ê³„íšì„œ": "ë°€íê³µê°„ì‘ì—…ê³„íšì„œ", "ë°€íê³µê°„ ì‘ì—… ê³„íšì„œ": "ë°€íê³µê°„ì‘ì—…ê³„íšì„œ",
    "ë°€íê³µê°„ì‘ì—… ê³„íšì„œ": "ë°€íê³µê°„ì‘ì—…ê³„íšì„œ", "ë°€íê³µê°„": "ë°€íê³µê°„ì‘ì—…ê³„íšì„œ",
    "ì •ì „ ì‘ì—… í—ˆê°€ì„œ": "ì •ì „ì‘ì—…í—ˆê°€ì„œ", "ì •ì „ì‘ì—…": "ì •ì „ì‘ì—…í—ˆê°€ì„œ",
    "í•´ì²´ ì‘ì—…ê³„íšì„œ": "í•´ì²´ì‘ì—…ê³„íšì„œ", "í•´ì²´ ê³„íšì„œ": "í•´ì²´ì‘ì—…ê³„íšì„œ",
    "êµ¬ì¡°ë¬¼ í•´ì²´ ê³„íš": "í•´ì²´ì‘ì—…ê³„íšì„œ", "í•´ì²´ì‘ì—…": "í•´ì²´ì‘ì—…ê³„íšì„œ",
    "í¬ë ˆì¸ ê³„íšì„œ": "í¬ë ˆì¸ì‘ì—…ê³„íšì„œ", "í¬ë ˆì¸ ì‘ì—… ê³„íšì„œ": "í¬ë ˆì¸ì‘ì—…ê³„íšì„œ",
    "ì–‘ì¤‘ê¸° ì‘ì—…ê³„íšì„œ": "í¬ë ˆì¸ì‘ì—…ê³„íšì„œ",
    "ê³ ì˜¨ ì‘ì—… í—ˆê°€ì„œ": "ê³ ì˜¨ì‘ì—…í—ˆê°€ì„œ", "ê³ ì˜¨ì‘ì—…": "ê³ ì˜¨ì‘ì—…í—ˆê°€ì„œ",
    "í™”ê¸°ì‘ì—… í—ˆê°€ì„œ": "í™”ê¸°ì‘ì—…í—ˆê°€ì„œ", "í™”ê¸° ì‘ì—…ê³„íšì„œ": "í™”ê¸°ì‘ì—…í—ˆê°€ì„œ", "í™”ê¸°ì‘ì—…": "í™”ê¸°ì‘ì—…í—ˆê°€ì„œ",
    "ì „ê¸° ì‘ì—…ê³„íšì„œ": "ì „ê¸°ì‘ì—…ê³„íšì„œ", "ì „ê¸° ê³„íšì„œ": "ì „ê¸°ì‘ì—…ê³„íšì„œ", "ì „ê¸°ì‘ì—…": "ì „ê¸°ì‘ì—…ê³„íšì„œ",
    "êµ´ì°©ê¸° ì‘ì—…ê³„íšì„œ": "êµ´ì°©ê¸°ì‘ì—…ê³„íšì„œ", "êµ´ì°©ê¸° ê³„íšì„œ": "êµ´ì°©ê¸°ì‘ì—…ê³„íšì„œ", "êµ´ì‚­ê¸° ì‘ì—…ê³„íšì„œ": "êµ´ì°©ê¸°ì‘ì—…ê³„íšì„œ",
    "ìš©ì ‘ì‘ì—… ê³„íšì„œ": "ìš©ì ‘ìš©ë‹¨ì‘ì—…í—ˆê°€ì„œ", "ìš©ì ‘ìš©ë‹¨ ê³„íšì„œ": "ìš©ì ‘ìš©ë‹¨ì‘ì—…í—ˆê°€ì„œ", "ìš©ì ‘ì‘ì—…": "ìš©ì ‘ìš©ë‹¨ì‘ì—…í—ˆê°€ì„œ",
    "ì „ê¸° ì‘ì—… í—ˆê°€ì„œ": "ì „ê¸°ì‘ì—…í—ˆê°€ì„œ", "ê³ ì•• ì „ê¸°ì‘ì—… ê³„íšì„œ": "ì „ê¸°ì‘ì—…í—ˆê°€ì„œ", "ì „ê¸° í—ˆê°€ì„œ": "ì „ê¸°ì‘ì—…í—ˆê°€ì„œ",
    "ë¹„ê³„ ì‘ì—… ê³„íšì„œ": "ë¹„ê³„ì‘ì—…ê³„íšì„œ", "ë¹„ê³„ ê³„íšì„œ": "ë¹„ê³„ì‘ì—…ê³„íšì„œ", "ë¹„ê³„ì‘ì—…ê³„íš": "ë¹„ê³„ì‘ì—…ê³„íšì„œ",
    "í˜‘ì°© ì‘ì—… ê³„íšì„œ": "í˜‘ì°©ìœ„í—˜ì‘ì—…ê³„íšì„œ", "í˜‘ì°© ê³„íšì„œ": "í˜‘ì°©ìœ„í—˜ì‘ì—…ê³„íšì„œ",
    "ì–‘ì¤‘ ì‘ì—… ê³„íšì„œ": "ì–‘ì¤‘ì‘ì—…ê³„íšì„œ", "ì–‘ì¤‘ê¸° ì‘ì—…ê³„íšì„œ": "ì–‘ì¤‘ì‘ì—…ê³„íšì„œ",
    "ê³ ì••ê°€ìŠ¤ ì‘ì—… ê³„íšì„œ": "ê³ ì••ê°€ìŠ¤ì‘ì—…ê³„íšì„œ", "ê³ ì••ê°€ìŠ¤ ê³„íšì„œ": "ê³ ì••ê°€ìŠ¤ì‘ì—…ê³„íšì„œ"
}

TEMPLATES = {
    name: {"columns": ["ì‘ì—… í•­ëª©", "ì‘ì„± ì–‘ì‹", "ì‹¤ë¬´ ì˜ˆì‹œ"], "drop_columns": []}
    for name in KEYWORD_ALIAS.values()
}
SOURCES = {
    name: f"â€» ë³¸ ì–‘ì‹ì€ {name} ê´€ë ¨ ë²•ë ¹ ë˜ëŠ” ì§€ì¹¨ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
    for name in KEYWORD_ALIAS.values()
}

def resolve_keyword(raw_keyword: str) -> str:
    for alias, std in KEYWORD_ALIAS.items():
        if alias in raw_keyword:
            return std
    return raw_keyword

@app.route("/", methods=["GET"])
def index():
    return "ğŸ“° ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸: /daily_news, /render_news, /create_xlsx", 200

# XLSX ìƒì„±
@app.route("/create_xlsx", methods=["GET"])
def create_xlsx():
    raw = request.args.get("template", "")
    tpl = resolve_keyword(raw)
    if tpl not in TEMPLATES:
        return {"error": f"'{raw}' ì–‘ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, 400

    csv_path = os.path.join(DATA_DIR, f"{tpl}.csv")
    if not os.path.exists(csv_path):
        return {"error": "CSV ì›ë³¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}, 404

    df = pd.read_csv(csv_path)
    df = df.drop(columns=TEMPLATES[tpl]["drop_columns"], errors="ignore")
    df = df[[c for c in TEMPLATES[tpl]["columns"] if c in df.columns]]

    source = SOURCES.get(tpl)
    if source:
        df.loc[len(df)] = [source] + [""] * (len(df.columns) - 1)

    xlsx_path = os.path.join(DATA_DIR, f"{tpl}_ìµœì¢…ì–‘ì‹.xlsx")
    df.to_excel(xlsx_path, index=False)
    return send_file(xlsx_path, as_attachment=True, download_name=f"{tpl}.xlsx")

# SafetyNews ë³¸ë¬¸ ì¶”ì¶œ
def fetch_safetynews_article_content(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        node = soup.select_one("div#article-view-content-div")
        return node.get_text("\n").strip() if node else "(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"
    except Exception:
        return "(ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨)"

# ë„¤ì´ë²„ ë‰´ìŠ¤ Open API í¬ë¡¤ë§
def crawl_naver_news():
    base_url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }
    keywords = [
        "ê±´ì„¤ ì‚¬ê³ ", "ê±´ì„¤ ì‚¬ë§ì‚¬ê³ ", "ì¶”ë½ ì‚¬ê³ ", "ë¼ì„ ì‚¬ê³ ",
        "ì§ˆì‹ ì‚¬ê³ ", "í­ë°œ ì‚¬ê³ ", "ì‚°ì—…ì¬í•´", "ì‚°ì—…ì•ˆì „"
    ]
    out = []
    for kw in keywords:
        params = {"query": kw, "display": 2, "sort": "date"}
        resp = requests.get(base_url, headers=headers, params=params, timeout=10)
        if resp.status_code != 200:
            continue
        for item in resp.json().get("items", []):
            title   = BeautifulSoup(item.get("title",""), "html.parser").get_text()
            desc    = BeautifulSoup(item.get("description",""), "html.parser").get_text()
            link    = item.get("link","")
            pubdate = item.get("pubDate","")  # e.g. "Tue, 28 Apr 2025 07:00:00 +0900"
            out.append({
                "ì¶œì²˜": item.get("originallink","ë„¤ì´ë²„"),
                "ì œëª©": title,
                "ë§í¬": link,
                "ë‚ ì§œ": pubdate,
                "ë³¸ë¬¸": desc
            })
    return out

# SafetyNews í¬ë¡¤ë§
def crawl_safetynews():
    base = "https://www.safetynews.co.kr"
    keywords = [
        "ê±´ì„¤ ì‚¬ê³ ", "ê±´ì„¤ ì‚¬ë§ì‚¬ê³ ", "ì¶”ë½ ì‚¬ê³ ", "ë¼ì„ ì‚¬ê³ ",
        "ì§ˆì‹ ì‚¬ê³ ", "í­ë°œ ì‚¬ê³ ", "ì‚°ì—…ì¬í•´", "ì‚°ì—…ì•ˆì „"
    ]
    out = []
    for kw in keywords:
        resp = requests.get(
            f"{base}/search/news?searchword={kw}",
            headers={"User-Agent": "Mozilla/5.0"},
            timeout=10
        )
        if resp.status_code != 200:
            continue
        soup = BeautifulSoup(resp.text, "html.parser")
        for item in soup.select(".article-list-content")[:2]:
            t    = item.select_one(".list-titles")
            href = base + t["href"] if t and t.get("href") else None
            d    = item.select_one(".list-dated")
            content = fetch_safetynews_article_content(href) if href else ""
            out.append({
                "ì¶œì²˜": "ì•ˆì „ì‹ ë¬¸",
                "ì œëª©": t.get_text(strip=True) if t else "",
                "ë§í¬": href,
                "ë‚ ì§œ": d.get_text(strip=True) if d else "",
                "ë³¸ë¬¸": content[:1000]
            })
    return out

# â¶ ì›ë³¸ ë‰´ìŠ¤ JSON ë°˜í™˜
@app.route("/daily_news", methods=["GET"])
def get_daily_news():
    news = crawl_naver_news() + crawl_safetynews()
    if not news:
        return jsonify({"error": "ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."}), 200
    return jsonify(news)

# â· GPT í¬ë§·íŒ… ë‰´ìŠ¤ ë°˜í™˜ (ìµœì‹  3ì¼ ì´ë‚´, ìµœëŒ€ 3ê°œ)
@app.route("/render_news", methods=["GET"])
def render_news():
    raw = crawl_naver_news() + crawl_safetynews()
    # 3ì¼ ì „ cutoff
    cutoff = datetime.utcnow() - timedelta(days=3)
    filtered = []
    for n in raw:
        try:
            dt = parser.parse(n["ë‚ ì§œ"])
        except Exception:
            continue
        if dt >= cutoff:
            # ë‚ ì§œ í¬ë§· í†µì¼
            n["ë‚ ì§œ"] = dt.strftime("%Y.%m.%d")
            filtered.append(n)
    # ìµœì‹ ìˆœ ì •ë ¬ ë° ìµœëŒ€ 3ê°œ
    news_items = sorted(filtered, key=lambda x: parser.parse(x["ë‚ ì§œ"]), reverse=True)[:3]

    if not news_items:
        return jsonify({"error": "ê°€ì ¸ì˜¬ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."}), 200

    template_text = (
        "ğŸ“Œ ì‚°ì—… ì•ˆì „ ë° ë³´ê±´ ìµœì‹  ë‰´ìŠ¤\n"
        "ğŸ“° â€œ{title}â€ ({date}, {source})\n\n"
        "{headline}\n"
        "ğŸ” {recommendation}\n"
        "ğŸ‘‰ ìš”ì•½ ì œê³µë¨ Â· â€œë‰´ìŠ¤ ë” ë³´ì—¬ì¤˜â€ ì…ë ¥ ì‹œ ìœ ì‚¬ ì‚¬ë¡€ ì¶”ê°€ í™•ì¸ ê°€ëŠ¥"
    )
    system_message = {
        "role": "system",
        "content": (
            "ë‹¤ìŒ JSON í˜•ì‹ì˜ ë‰´ìŠ¤ ëª©ë¡ì„ ì•„ë˜ í…œí”Œë¦¿ì— ë§ì¶° 3ê°œ í•­ëª© ì¶œë ¥í•˜ì„¸ìš”.\n"
            f"í…œí”Œë¦¿:\n{template_text}"
        )
    }
    user_message = {"role": "user", "content": str(news_items)}

    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[system_message, user_message],
        max_tokens=800,
        temperature=0.7
    )
    output = resp.choices[0].message.content
    return jsonify({"formatted_news": output})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
